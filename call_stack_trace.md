# Call Stack Trace: Pipeline Execution Flows

## **Pipeline Command Examples**

```bash
# Experiment Mode
uv run pipeline run --experiment -n 10 -s key_value_with_images

# Normal Mode
uv run pipeline run -n 100 -s key_value_with_images
```

---

## **ğŸ§ª EXPERIMENT PIPELINE FLOW**

**Purpose:** Compare strategies without persisting to database, with MLflow tracking

### **Abstraction Levels & Order of Operations:**

```python
ğŸ¯ LEVEL 1: CLI Interface
â”œâ”€â–º app/process/cli/pipeline.py:run()
    â””â”€â–º Parses arguments, detects --experiment flag

ğŸ¯ LEVEL 2: Pipeline Orchestration  
â”œâ”€â–º app/process/cli/pipeline.py:_run_async()
    â”œâ”€â–º Experiment Mode Branch: 
    â””â”€â–º result = await ExperimentRunner.run_embedding_experiment(...)

ğŸ¯ LEVEL 3: Experiment Management
â”œâ”€â–º app/process/experiments/runner.py:ExperimentRunner.run_embedding_experiment()
    â”œâ”€â–º Creates EmbeddingExperiment instance
    â””â”€â–º return await experiment.execute()

ğŸ¯ LEVEL 4: Experiment Execution Framework
â”œâ”€â–º app/process/experiments/runner.py:EmbeddingExperiment.execute()
    â”œâ”€â–º Setup MLflow tracking
    â”œâ”€â–º Start MLflow run
    â”œâ”€â–º results = await self.run()
    â”œâ”€â–º Log artifacts & metrics
    â””â”€â–º Return experiment results

ğŸ¯ LEVEL 5: Strategy Comparison Logic
â”œâ”€â–º app/process/experiments/runner.py:EmbeddingExperiment.run()
    â”œâ”€â–º Load raw JSON data (no DB interaction)
    â”œâ”€â–º For each strategy in self.strategies:
    â”‚   â””â”€â–º await self.run_single_strategy(strategy, session)
    â”œâ”€â–º Generate comparison metrics
    â””â”€â–º Create visualizations

ğŸ¯ LEVEL 6: Individual Strategy Processing  
â”œâ”€â–º app/process/experiments/runner.py:EmbeddingExperiment.run_single_strategy()
    â”œâ”€â–º Get strategy instance
    â”œâ”€â–º Initialize metrics collection
    â”œâ”€â–º For each product in batch:
    â”‚   â”œâ”€â–º ğŸ¯ IMAGE ANALYSIS (if key_value_with_images):
    â”‚   â”‚   â””â”€â–º await extract_enhanced_fashion_analysis()
    â”‚   â”‚       â””â”€â–º ğŸš€ OPENAI VISION API CALL
    â”‚   â”œâ”€â–º text = strategy_instance.generate(product_data, image_analysis=analysis)
    â”‚   â””â”€â–º Store text & metrics
    â””â”€â–º Generate embeddings for all texts

ğŸ¯ LEVEL 7: Strategy Text Generation
â”œâ”€â–º app/process/strategies/text_strategies.py:KeyValueWithImagesStrategy.generate()
    â”œâ”€â–º base_text = super().generate(product, **kwargs)
    â”œâ”€â–º image_analysis = kwargs.get('image_analysis')
    â”œâ”€â–º If image_analysis: enrich text with visual data
    â””â”€â–º Return enriched text

ğŸ¯ LEVEL 8: Embedding Generation (Batch)
â”œâ”€â–º app/process/core/embedding_generator.py:generate_embeddings_batch()
    â”œâ”€â–º For each text in batch:
    â”‚   â””â”€â–º embedding = await self.generate_embedding(text)
    â””â”€â–º Return list of embeddings

ğŸ¯ LEVEL 9: Individual Embedding API
â”œâ”€â–º app/process/core/embedding_generator.py:generate_embedding()
    â””â”€â–º response = await self.client.embeddings.create(...)
        â””â”€â–º ğŸš€ OPENAI EMBEDDING API CALL
```

---

## **ğŸ­ NORMAL PIPELINE FLOW**

**Purpose:** Process and persist products to database for production use

### **Abstraction Levels & Order of Operations:**

```python
ğŸ¯ LEVEL 1: CLI Interface
â”œâ”€â–º app/process/cli/pipeline.py:run()
    â””â”€â–º Parses arguments, no --experiment flag

ğŸ¯ LEVEL 2: Pipeline Orchestration
â”œâ”€â–º app/process/cli/pipeline.py:_run_async()
    â”œâ”€â–º Normal Mode Branch:
    â”œâ”€â–º config = PipelineConfig(...)
    â””â”€â–º result = await run_pipeline(config)

ğŸ¯ LEVEL 3: Core Pipeline Management
â”œâ”€â–º app/process/core/pipeline.py:run_pipeline()
    â”œâ”€â–º Create DataPipeline instance
    â””â”€â–º return await pipeline.execute()

ğŸ¯ LEVEL 4: Data Pipeline Execution
â”œâ”€â–º app/process/core/pipeline.py:DataPipeline.execute()
    â”œâ”€â–º Load raw JSON data
    â”œâ”€â–º Initialize database
    â”œâ”€â–º Create ProductLoader instance
    â””â”€â–º await loader.load_products_batch(products_data)

ğŸ¯ LEVEL 5: Product Batch Loading
â”œâ”€â–º app/process/core/product_loader.py:ProductLoader.load_products_batch()
    â”œâ”€â–º For each batch of products:
    â”‚   â”œâ”€â–º First Pass: Load products to DB
    â”‚   â”‚   â””â”€â–º For each product: await self.load_product(product_data)
    â”‚   â”œâ”€â–º await session.commit()  # Get product IDs
    â”‚   â”œâ”€â–º Second Pass: Generate embeddings
    â”‚   â”‚   â””â”€â–º For each product: await self.generate_embeddings_for_product()
    â”‚   â””â”€â–º await session.commit()  # Save embeddings
    â””â”€â–º Return (loaded_count, failed_count)

ğŸ¯ LEVEL 6: Individual Product Processing
â”œâ”€â–º app/process/core/product_loader.py:ProductLoader.load_product()
    â”œâ”€â–º Check if product exists in DB
    â”œâ”€â–º Create Product model instance
    â”œâ”€â–º Add ProductImage & ProductVideo instances
    â””â”€â–º session.add(product)

ğŸ¯ LEVEL 7: Embedding Generation Per Product
â”œâ”€â–º app/process/core/product_loader.py:generate_embeddings_for_product()
    â”œâ”€â–º ğŸ¯ IMAGE ANALYSIS (always performed):
    â”‚   â””â”€â–º image_analysis = await self.analyze_product_images(product)
    â”‚       â””â”€â–º await extract_enhanced_fashion_analysis()
    â”‚           â””â”€â–º ğŸš€ OPENAI VISION API CALL
    â”œâ”€â–º For each strategy in strategies:
    â”‚   â”œâ”€â–º strategy = get_strategy(strategy_name)
    â”‚   â”œâ”€â–º If strategy needs images: text = strategy.generate(data, image_analysis=analysis)
    â”‚   â”œâ”€â–º Else: text = strategy.generate(data)
    â”‚   â”œâ”€â–º embedding = await embedding_generator.generate_embedding(text)
    â”‚   â”‚   â””â”€â–º ğŸš€ OPENAI EMBEDDING API CALL
    â”‚   â””â”€â–º Create ProductEmbedding model & session.add()
    â””â”€â–º Store analysis in database

ğŸ¯ LEVEL 8: Strategy Text Generation (Same as Experiment)
â”œâ”€â–º app/process/strategies/text_strategies.py:Strategy.generate()
    â””â”€â–º Generate structured text based on strategy type

ğŸ¯ LEVEL 9: Database Persistence
â”œâ”€â–º SQLAlchemy Models (Product, ProductEmbedding, ProductImage, etc.)
    â””â”€â–º session.commit() â†’ PostgreSQL database
```

---

## **ğŸ“Š KEY DIFFERENCES**

| Aspect | **Experiment Pipeline** | **Normal Pipeline** |
|--------|------------------------|-------------------|
| **Purpose** | Strategy comparison & analysis | Production data loading |
| **Data Source** | Raw JSON (in-memory) | Raw JSON â†’ Database models |
| **Database** | Read-only session | Full CRUD operations |
| **Image Analysis** | Only for strategies that need it | Always performed & stored |
| **MLflow Tracking** | Full experiment tracking | Optional metrics only |
| **Persistence** | Temporary artifacts only | Full database persistence |
| **Batch Processing** | In-memory batches | Database transaction batches |
| **Error Handling** | Continue with failures | Robust transaction rollback |
| **Performance Focus** | Comparison metrics | Throughput & reliability |
| **Output** | Experiment reports & visualizations | Database records |

## **ğŸ” ISSUE DISCOVERED AND RESOLVED: Image Analysis Integration in Experiments**

**PROBLEM IDENTIFIED:**
Looking at the code flow, the OpenAI image analysis (`extract_enhanced_fashion_analysis`) was only called in:

**File:** `app/process/core/product_loader.py:generate_embeddings_for_product()`

But this method was only called when using `ProductLoader.load_products_batch()` for **actual database loading**, NOT during experiments!

The experiment runner was using a different path:
- `EmbeddingExperiment.run_single_strategy()` 
- Called `strategy.generate(product_data)` directly
- **No image analysis passed** (no `image_analysis` kwarg)

**WHY KeyValueWithImages Strategy Showed Misleading Performance:**
It was fast because **no actual image analysis was happening** in experiments - it just fell back to the base KeyValue strategy text without image enrichment!

**SOLUTION IMPLEMENTED:**
Modified `app/process/experiments/runner.py` to:

1. **Detect strategies that need image analysis**: Check if strategy is `key_value_with_images`
2. **Initialize OpenAI client when needed**: Create client for image analysis
3. **Call image analysis for each product**: Extract enhanced fashion analysis from product images
4. **Pass analysis to strategy**: Provide `image_analysis` parameter to strategy.generate()
5. **Track image analysis metrics**: Log success rate, API call count, and confidence scores

**VERIFICATION:**
âœ… Ran experiment with `uv run pipeline run --experiment -n 10 -s key_value_with_images`
âœ… **10/10 image analyses successful (100.0%)**
âœ… **Average text length: 783 chars (much higher with image data)**
âœ… **Average tokens: 216 (showing image enrichment is working)**
âœ… **Proper API call tracking and confidence logging**

The expensive OpenAI vision calls now happen during **both** experiment comparisons AND real data loading, providing accurate performance comparisons!
